<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print" />

    <title>PracticalMachineLearning by clausia</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>PracticalMachineLearning</h1>
        <h2>.:Prediction Assignment Writeup:.</h2>

        <section id="downloads">
          <a href="https://github.com/clausia/PracticalMachineLearning/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/clausia/PracticalMachineLearning/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/clausia/PracticalMachineLearning" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
        <h3>
          <a name="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages">
            <span class="octicon octicon-link"></span>
          </a>
          Background
        </h3>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about 
personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of 
enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, 
or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, 
but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, 
forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 
different ways. More information is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a> 
(see the section on the Weight Lifting Exercise Dataset).</p>

        <h3>
          <a name="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages">
            <span class="octicon octicon-link"></span>
          </a>
          Data
        </h3>

<p>
The training data for this project are available here:
<br>
<br>
<a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv</a>
<br><br>
The test data are available here: 
<br><br>
<a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv</a>
<br><br>
The data for this project come from this source: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>. 
If you use the document you create for this class for any purpose please cite them as they have been very generous in 
allowing their data to be used for this kind of assignment.
</p>

        <h3>
          <a name="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages">
            <span class="octicon octicon-link"></span>
          </a>
          Analysis
        </h3>

<p>
First we will get rid of the variables having high missing values. After making sure that, now we have variables 
which do not have any missing values we will look for variables with very high correlation, because these highly 
correlated varibles can lead to multicollinearity which can increase miss classification error rate. Now as of now 
we have only 32 Variables that can used for prediction.
</p><p>
The next big quest is choosing the right algorithm which learns from the data to its best. Without much effort 
and extensively exploring the forums I found out that randomForest will be the best choice for the data, which 
uses the bragging method that is a high variance, low bias technique.
The learned algorithm from this data is then used to predict the test data.
</p>

        <h3>
          <a name="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages">
            <span class="octicon octicon-link"></span>
          </a>
          Importing data and libraries
        </h3>

<pre><code>
library(caret)
library(lattice)
library(ggplot2)
library(reshape)
library(corrplot)
library(AppliedPredictiveModeling)

traininig<-read.csv("pml-traininig.csv",stringsAsFactor=FALSE,skip=0,fill=NA,comment.char="#")
testing<-read.csv("pml-testinging.csv")
</code></pre>


        <h3>
          <a name="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages">
            <span class="octicon octicon-link"></span>
          </a>
          Removing Missing data Variables
        </h3>

<pre><code>
var<-names(traininig)[apply(traininig,2,function(x) table(is.na(x))[1]==19622)]   
traininig2<-traininig[,var]
testing2<-testing[,var[-length(var)]]
var2<-melt(apply(traininig2,2,function(x) sum(ifelse(x=="",1,0)))==0)
select.var<-rownames(var2)[var2$value==TRUE]
traininig3<-traininig2[,select.var]
testing3<-testing2[,select.var[-length(select.var)]]
traininig4<-traininig3[,names(traininig3[-c(1:7,length(traininig3))])]
testing4<-testing3[,names(testing3[-c(1:7)])]
</code></pre>

<p>
Looking for correlations within numeric variables to remove multicollinearity
</p>

<pre><code>
correlations <- cor(traininig4)
corrplot(correlations,order = "hclust",tl.cex = .5)
</code></pre>

<img src="https://cloud.githubusercontent.com/assets/1554515/3352729/d810b7f0-fa57-11e3-8809-2f8a0a93ab73.png">

<pre><code>
highCorr <- findCorrelation(correlations, cutoff = .75)
predictor <- traininig4[, -highCorr]
filtered.testing4 <- testing4[, -highCorr]
classe<-traininig3$classe
traininigData<-cbind(classe,predictor)
</code></pre>


        <h3>
          <a name="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages">
            <span class="octicon octicon-link"></span>
          </a>
          Random Forest Algorithm
        </h3>

<pre><code>
rfModel <- randomForest(classe ~ .,data = traininigData,importance = TRUE,ntrees = 10)
par(mar=c(3,4,4,4)) 
plot(rfModel)
</code></pre>

<img src="https://cloud.githubusercontent.com/assets/1554515/3352730/d81e082e-fa57-11e3-9def-8d80b1838243.png">

<pre><code>
varImpPlot(rfModel,cex=.5) 
</code></pre>

<img src="https://cloud.githubusercontent.com/assets/1554515/3352728/d8021d12-fa57-11e3-9ab6-491cbf920be2.png">

<pre><code>
out.testing<-predict(rfModel,filtered.testing4)
</code></pre>

        <h3>
          <a name="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages">
            <span class="octicon octicon-link"></span>
          </a>
          Generating results
        </h3>

<pre><code>
answers<- as.vector(out.testing)
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(answers)
</code></pre>


      </section>
    </div>

    
  </body>
</html>
